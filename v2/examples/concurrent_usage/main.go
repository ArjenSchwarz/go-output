package main

import (
	"context"
	"fmt"
	"log"
	"sync"
	"time"

	output "github.com/ArjenSchwarz/go-output/v2"
)

func main() {
	fmt.Println("=== Concurrent Usage Demonstration ===")
	fmt.Println("This example shows v2's thread-safe operations")
	fmt.Println()

	// Example 1: Concurrent Document Building
	fmt.Println("Example 1: Thread-safe document building")

	var wg sync.WaitGroup
	results := make(chan *output.Document, 3)

	// Simulate 3 concurrent processes building documents
	for i := range 3 {
		wg.Add(1)
		go func(workerID int) {
			defer wg.Done()

			// Each worker builds its own document safely
			doc := output.New().
				SetMetadata("worker_id", workerID).
				SetMetadata("timestamp", time.Now().Unix()).
				Header(fmt.Sprintf("Worker %d Report", workerID)).
				Table(fmt.Sprintf("Data from Worker %d", workerID),
					generateWorkerData(workerID, 10),
					output.WithKeys("ID", "WorkerID", "Value", "Timestamp")).
				Text(fmt.Sprintf("Generated by worker %d", workerID)).
				Build()

			results <- doc
			fmt.Printf("✅ Worker %d completed document building\n", workerID)
		}(i)
	}

	// Wait for all workers to complete
	go func() {
		wg.Wait()
		close(results)
	}()

	// Collect results
	var docs []*output.Document
	for doc := range results {
		docs = append(docs, doc)
	}

	fmt.Printf("✅ All %d documents built concurrently\n\n", len(docs))

	// Example 2: Concurrent Rendering of Same Document
	fmt.Println("Example 2: Concurrent rendering to multiple formats")

	sharedDoc := output.New().
		Header("Concurrent Rendering Test").
		Table("Shared Data", []map[string]any{
			{"Format": "JSON", "ThreadSafe": "Yes", "Performance": "High"},
			{"Format": "CSV", "ThreadSafe": "Yes", "Performance": "High"},
			{"Format": "Table", "ThreadSafe": "Yes", "Performance": "High"},
		}, output.WithKeys("Format", "ThreadSafe", "Performance")).
		Build()

	// Create multiple output configurations
	formats := []output.Format{output.JSON, output.CSV, output.Table}
	var renderWG sync.WaitGroup
	renderResults := make(chan string, len(formats))

	for _, format := range formats {
		renderWG.Add(1)
		go func(f output.Format) {
			defer renderWG.Done()

			// Each goroutine renders the same document concurrently
			out := output.NewOutput(
				output.WithFormat(f),
				output.WithWriter(output.NewStdoutWriter()),
			)

			start := time.Now()
			if err := out.Render(context.Background(), sharedDoc); err != nil {
				renderResults <- fmt.Sprintf("❌ %s: %v", f.Name, err)
			} else {
				duration := time.Since(start)
				renderResults <- fmt.Sprintf("✅ %s: %v", f.Name, duration)
			}
		}(format)
	}

	// Wait for all renders
	go func() {
		renderWG.Wait()
		close(renderResults)
	}()

	// Collect render results
	fmt.Println("Concurrent render results:")
	for result := range renderResults {
		fmt.Printf("  %s\n", result)
	}
	fmt.Println()

	// Example 3: High-Concurrency Document Processing Pipeline
	fmt.Println("Example 3: High-concurrency processing pipeline")

	const numProducers = 5
	const numConsumers = 3
	const itemsPerProducer = 20

	// Channel for passing data between stages
	dataChannel := make(chan map[string]any, 100)
	docChannel := make(chan *output.Document, 50)

	// Stage 1: Data producers
	var producerWG sync.WaitGroup
	for i := range numProducers {
		producerWG.Add(1)
		go func(producerID int) {
			defer producerWG.Done()

			for j := range itemsPerProducer {
				data := map[string]any{
					"ID":        fmt.Sprintf("P%d-I%d", producerID, j),
					"Producer":  producerID,
					"Item":      j,
					"Value":     (producerID*1000 + j),
					"Generated": time.Now().Format("15:04:05.000"),
				}

				select {
				case dataChannel <- data:
				case <-time.After(100 * time.Millisecond):
					log.Printf("Producer %d timeout sending item %d", producerID, j)
				}
			}
			fmt.Printf("✅ Producer %d finished\n", producerID)
		}(i)
	}

	// Close data channel when all producers are done
	go func() {
		producerWG.Wait()
		close(dataChannel)
	}()

	// Stage 2: Document builders (consumers)
	var consumerWG sync.WaitGroup
	for i := range numConsumers {
		consumerWG.Add(1)
		go func(consumerID int) {
			defer consumerWG.Done()

			var batch []map[string]any
			batchSize := 10

			for data := range dataChannel {
				batch = append(batch, data)

				if len(batch) >= batchSize {
					// Build document from batch
					doc := output.New().
						Header(fmt.Sprintf("Consumer %d Batch", consumerID)).
						Table("Processed Data", batch,
							output.WithKeys("ID", "Producer", "Value", "Generated")).
						Text(fmt.Sprintf("Processed %d items", len(batch))).
						Build()

					docChannel <- doc
					batch = nil // Reset batch
				}
			}

			// Handle remaining items in batch
			if len(batch) > 0 {
				doc := output.New().
					Header(fmt.Sprintf("Consumer %d Final Batch", consumerID)).
					Table("Remaining Data", batch,
						output.WithKeys("ID", "Producer", "Value", "Generated")).
					Text(fmt.Sprintf("Final batch: %d items", len(batch))).
					Build()

				docChannel <- doc
			}

			fmt.Printf("✅ Consumer %d finished\n", consumerID)
		}(i)
	}

	// Close document channel when all consumers are done
	go func() {
		consumerWG.Wait()
		close(docChannel)
	}()

	// Stage 3: Document processor (render documents as they arrive)
	processedCount := 0
	for doc := range docChannel {
		processedCount++

		// Create output for each document
		out := output.NewOutput(
			output.WithFormat(output.JSON),
			output.WithWriter(&countingWriter{id: processedCount}),
		)

		if err := out.Render(context.Background(), doc); err != nil {
			log.Printf("Error rendering document %d: %v", processedCount, err)
		}
	}

	fmt.Printf("✅ Pipeline completed: processed %d documents\n\n", processedCount)

	// Summary
	fmt.Printf("Concurrency Features Demonstrated:\n")
	fmt.Printf("✓ Thread-safe document building (%d concurrent builders)\n", 3)
	fmt.Printf("✓ Concurrent rendering of shared documents (%d formats)\n", len(formats))
	fmt.Printf("✓ High-concurrency pipeline (%d producers, %d consumers)\n", numProducers, numConsumers)
	fmt.Printf("✓ Total items processed: %d\n", numProducers*itemsPerProducer)
	fmt.Printf("✓ No race conditions or data corruption\n")
	fmt.Printf("✓ Proper resource management and cleanup\n")
}

// generateWorkerData creates test data for a specific worker
func generateWorkerData(workerID, count int) []map[string]any {
	data := make([]map[string]any, count)
	for i := range count {
		data[i] = map[string]any{
			"ID":        fmt.Sprintf("W%d-R%d", workerID, i),
			"WorkerID":  workerID,
			"Value":     workerID*100 + i,
			"Timestamp": time.Now().Unix(),
		}
	}
	return data
}

// countingWriter is a test writer that just counts operations
type countingWriter struct {
	id int
}

func (c *countingWriter) Write(ctx context.Context, format string, data []byte) error {
	fmt.Printf("📝 Document %d rendered: %d bytes in %s format\n", c.id, len(data), format)
	return nil
}
